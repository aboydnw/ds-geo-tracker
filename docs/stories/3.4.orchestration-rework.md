# Story 3.4: Tracker Orchestration Rework

## Status
Draft

## Story
**As a** developer,
**I want** `index.js` refactored to support the new multi-source, multi-query tracking flow,
**so that** the tracker can iterate over enabled LLM sources, query each one per configured query, analyze responses, and send enriched events to Plausible.

## Context
The current `index.js` is a simple single loop: iterate queries → send a heartbeat event per query. The Epic 3 flow is fundamentally different: for each query, for each enabled LLM source, call the LLM API, analyze the response, score prominence, and send an enriched event. This story covers the orchestration glue code that ties together the source modules (Story 3.2/3.3), the analysis module (Story 3.2), and the Plausible integration (Story 3.1).

## Dependencies
- **Required:** Story 3.1 (Plausible event model with referrer/url support)
- **Required:** Story 3.2 (Perplexity source + shared analysis module + source interface definition)
- **Optional/concurrent:** Story 3.3 (additional LLM sources). The orchestrator works with whatever sources `getEnabledSources()` returns — it can ship with only Perplexity and gain new sources as Story 3.3 delivers them incrementally.

## Acceptance Criteria
1. `index.js` discovers enabled LLM sources via `getEnabledSources()` from `src/sources/index.js`
2. For each configured query, each enabled source is queried and the response is analyzed
3. Per-query, per-source results are sent to Plausible using the enriched event model from Story 3.1
4. Errors in one source or one query do not block other sources or queries
5. Summary output includes: total events, successes, failures, breakdown per source, total estimated cost
6. Rate limiting is respected per source (configurable delay between API calls to each LLM)
7. Exit code logic: exit 0 if ≥50% of events succeed, exit 1 otherwise (matches current behavior)
8. If no sources are enabled, log a clear warning and exit 0 (not a failure — just nothing to do)
9. Integration tests cover the full orchestration loop with mocked sources

## Tasks / Subtasks
- [ ] Refactor `index.js` orchestration (AC: 1, 2, 3)
  - [ ] Import `getEnabledSources()` from `src/sources/index.js`
  - [ ] Outer loop: iterate over queries
  - [ ] Inner loop: iterate over enabled sources
  - [ ] For each (query, source) pair: call `source.query(searchTerm)` → `analyzeResponse(result)` → `sendEventToPlausible(...)` with enriched props
  - [ ] Build Plausible event using source's `referrer`, analyzed `url`, and prominence props
- [ ] Implement error isolation (AC: 4)
  - [ ] Wrap each (query, source) call in try/catch
  - [ ] Log error with query name and source name, continue to next
  - [ ] Track failures per source for summary
- [ ] Implement per-source rate limiting (AC: 6)
  - [ ] Each source can define a `rateLimitMs` property (default: 1000ms)
  - [ ] Delay between consecutive API calls to the same source
  - [ ] Different sources can be called without delay between them (they hit different APIs)
- [ ] Update summary output (AC: 5)
  - [ ] Total events attempted: `queries.length × enabledSources.length`
  - [ ] Successes and failures
  - [ ] Per-source breakdown: `Perplexity: 7/7, ChatGPT: 6/7, ...`
  - [ ] Estimated cost per source and total (from usage data returned by each query)
  - [ ] Total duration
- [ ] Handle no-sources-enabled case (AC: 8)
  - [ ] If `getEnabledSources()` returns empty, log warning and exit 0
  - [ ] Suggest which env vars to set in the log message
- [ ] Write tests (AC: 9)
  - [ ] `index.test.js` or `src/orchestrator.test.js` with mocked sources and mocked Plausible
  - [ ] Test: 2 queries × 2 sources → 4 events sent
  - [ ] Test: one source throws on one query → other queries and sources still complete
  - [ ] Test: no sources enabled → clean exit with warning
  - [ ] Test: exit code 1 when >50% failures

## Dev Notes

### New Flow
```
index.js
  ├── Load queries from src/queries.js
  ├── Get enabled sources from src/sources/index.js
  ├── For each query:
  │   ├── For each enabled source:
  │   │   ├── source.query(searchTerm) → normalized result
  │   │   ├── analyzeResponse(result) → prominence data
  │   │   ├── sendEventToPlausible('GEO_Query_Tracked', props, { referrer, url })
  │   │   └── Rate limit delay (per source)
  │   └── (next source)
  └── Print summary
```

### Suggested Refactor: Extract Orchestrator
Consider extracting the core loop into `src/orchestrator.js` and keeping `index.js` as a thin entry point (load config, call orchestrator, handle exit code). This makes the orchestration logic testable without dealing with `process.exitCode` or `dotenv/config` side effects.

```javascript
// src/orchestrator.js
export async function runTracker(queries, sources) {
  const results = { total: 0, success: 0, failed: 0, perSource: {}, cost: 0 };
  // ... orchestration loop ...
  return results;
}

// index.js
import 'dotenv/config';
import queries from './src/queries.js';
import { getEnabledSources } from './src/sources/index.js';
import { runTracker } from './src/orchestrator.js';

const sources = getEnabledSources();
const results = await runTracker(queries, sources);
// ... summary output and exit code ...
```

### Rate Limiting Strategy
Different LLM APIs have different rate limits. Rather than a global delay, each source declares its own:
```javascript
export default {
  name: 'Perplexity',
  referrer: 'https://perplexity.ai',
  rateLimitMs: 1000,  // 1s between calls to Perplexity
  enabled: () => !!process.env.PERPLEXITY_API_KEY,
  async query(searchTerm) { ... }
};
```
The orchestrator reads `source.rateLimitMs` and delays accordingly between consecutive calls to the same source. Calls to different sources don't need delays between each other.

### Cost Tracking
Each source's `query()` returns `usage` in the normalized result. The orchestrator accumulates this:
```javascript
// Per source, track total tokens and estimated cost
perSource['Perplexity'].totalTokens += result.usage.totalTokens;
perSource['Perplexity'].estimatedCost += estimateCost(source.name, result.usage);
```
Cost-per-token rates can live in each source module or in a shared config.

### Testing Strategy
The orchestrator is the most testable part because it accepts its dependencies (queries, sources) as arguments:
```javascript
// In tests:
const mockSource = {
  name: 'MockLLM',
  referrer: 'https://mock.ai',
  rateLimitMs: 0,
  enabled: () => true,
  query: async (term) => ({
    content: 'Development Seed makes titiler',
    citations: ['https://developmentseed.org/blog/titiler-v2'],
    searchResults: [],
    usage: { promptTokens: 50, completionTokens: 200, totalTokens: 250 },
  }),
};
const results = await runTracker([queries[0]], [mockSource]);
assert.strictEqual(results.total, 1);
assert.strictEqual(results.success, 1);
```

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2026-02-08 | 0.1 | Story created for orchestration rework | Review |
